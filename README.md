# webCrawler
获取当前租房网站的房源信息


2020/3/16

1、中间件中设置随机代理

2、分析目标网站
    
    链家北京信息第一页    https://bj.lianjia.com/zufang/pg1/#contentList
               第二页    https://bj.lianjia.com/zufang/pg2/#contentList
    因此需要拼接页数

2020/3/25
  
1、使用管道将数据存储到远程数据库之中

2、发现的问题：链家爬虫只显示三千条数据，其他的会隐藏，无法获取。所有可能要更改代码，
解决这个问题。例如对每个区域进行手动输入链接，对每个区域进行开始爬虫，但仍然获取不了全部信息
。网上有将小区作为链接开始进行爬取，但小区数量有几百个，挨个获取连接太麻烦。

3、待解决问题：增量爬虫，设置对比算法，对每日爬取数据进行对比，新增数据添加数据库，修改的数据进行更改。