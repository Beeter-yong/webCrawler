# webCrawler
获取当前租房网站的房源信息


2020/3/16

1、中间件中设置随机代理

2、分析目标网站
    
    链家北京信息第一页    https://bj.lianjia.com/zufang/pg1/#contentList
               第二页    https://bj.lianjia.com/zufang/pg2/#contentList
    因此需要拼接页数

2020/3/25
  
1、使用管道将数据存储到远程数据库之中

2、发现的问题：链家爬虫只显示三千条数据，其他的会隐藏，无法获取。所有可能要更改代码，
解决这个问题。例如对每个区域进行手动输入链接，对每个区域进行开始爬虫，但仍然获取不了全部信息
。网上有将小区作为链接开始进行爬取，但小区数量有几百个，挨个获取连接太麻烦。

3、待解决问题：增量爬虫，设置对比算法，对每日爬取数据进行对比，新增数据添加数据库，修改的数据进行更改。

4、已经解决了增量问题，即在管道中先查询数据库有无此数据，没有数据才会添加到数据库

2020/3/26

1、添加商圈链接到数据库中，目的是以后根据商圈链接找到商圈的小区并且获取信息。需要注意链家商圈295个左右，
但是有许多商圈在不同的行政区的名字相同，相同名字的商圈的链接共用，所以我们对相同名字的商圈只爬取一次。
    